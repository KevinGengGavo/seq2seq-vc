
###########################################################
#                  FINE-TUNING SETTING                    #
###########################################################
init-mods: ["encoder", "decoder", "feat_out", "prob_out", "postnet"]
freeze-mods: null

###########################################################
#                   INFERENCE SETTING                     #
###########################################################
vocoder:
    checkpoint: /home/kevingenghaopeng/vocoder/ParallelWaveGAN/egs/V001/voc_all/exp/train_nodev_parallel_wavegan.v1/checkpoint-250000steps.pkl
    config: /home/kevingenghaopeng/vocoder/ParallelWaveGAN/egs/V001/voc_all/exp/train_nodev_parallel_wavegan.v1/config.yml
    stats: /home/kevingenghaopeng/vocoder/ParallelWaveGAN/egs/V001/voc_all/exp/train_nodev_parallel_wavegan.v1/stats.h5
inference:
    threshold: 0.5    # threshold to stop the generation
    maxlenratio: 6.0 # maximum length of generated samples = input length * maxlenratio
    minlenratio: 0.0  # minimum length of generated samples = input length * minlenratio

###########################################################
#                  DATA LOADER SETTING                    #
###########################################################
batch_size: 100             # Batch size.
pin_memory: true            # Whether to pin memory in Pytorch DataLoader.
num_workers: 1              # Number of workers in Pytorch DataLoader.
allow_cache: true           # Whether to allow cache in dataset. If true, it requires cpu memory.

###########################################################
#             OPTIMIZER & SCHEDULER SETTING               #
###########################################################
optimizer_type: Adam
optimizer_params:
    lr: 0.00008              # Learning rate. See https://github.com/espnet/espnet/blob/master/espnet2/schedulers/noam_lr.py#L49-L50
grad_norm: 1.0              # Gradient norm.
scheduler: warmuplr
scheduler_params:
    warmup_steps: 4000      # Scheduler warm up step

###########################################################
#                    INTERVAL SETTING                     #
###########################################################
train_max_steps: 50000                 # Number of training steps.
save_interval_steps: 5000               # Interval steps to save checkpoint.
eval_interval_steps: 100               # Interval steps to evaluate the network.
log_interval_steps: 10                 # Interval steps to record the training log.

###########################################################
#                      LOSS SETTING                       #
###########################################################
trainer_type: ARVCTrainer
collater_type: ARVCCollater
criterions:
    "Seq2SeqLoss":
        bce_pos_weight: 10.0

###########################################################
#                      LOSS SETTING                       #
###########################################################
trainer_type: ARVCTrainer
collater_type: ARVCCollater
criterions:
    "Seq2SeqLoss":
        bce_pos_weight: 10.0
